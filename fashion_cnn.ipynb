{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d342059f",
   "metadata": {},
   "source": [
    "# Fashion MNIST: A Multi-Class Classification Problem\n",
    "We will create a multi-class CNN to solve a multi-class classification problem. Fashion MNIST is intended as a drop-in replacement for the classic MNIST dataset - a handwriting digit dataset often used as a \"Hello World\" dataset for machine learning. Fashion MNIST contains fashion item images, which turns out to be more challenging than MNIST.  \n",
    "\n",
    "Fashion MNIST contains 60,000 training images and 10,000 test images, 28 x 28 pixels each, with 10 categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186ff95",
   "metadata": {},
   "source": [
    "## 0. Environment\n",
    "\n",
    "This can be run both locally and colab. If you are going to run it locally, don't forget to create a virtual environment. Running it on colab, requires the colab extension. Then selecte kernek -> colab and go through the log in process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cea68a",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "Keras provides some utility functions to fetch and load some commonly used datasets, including Fashin MNIST. The `load_data()` method directly splits the training and test set. \n",
    "\n",
    "Since the class names are not included with the dataset, store them here to use later when plotting the images.\n",
    "\n",
    "We will explore the format of the dataset, the data type of the input images, also display a few images to have a first impression of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8fd7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      " There are 60000 images which are 28 x 28 pixels. These are for training.\n",
      " We also have 60000 labels for each image.\n",
      " An exampe of a label for the first image is 9 which corresponds to Ankle boot\n",
      " There are 10000 images which are 28 x 28 pixels. These are for testing.\n",
      "uint8 0 9 (60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist # Pip install both keras and tensor flow in the venv\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "n_classes = 10\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Inspect data\n",
    "print(f\" There are {X_train.shape[0]} images which are {X_train.shape[1]} x {X_train.shape[2]} pixels. These are for training.\")\n",
    "print(f\" We also have {y_train.shape[0]} labels for each image.\")\n",
    "print(f\" An exampe of a label for the first image is {y_train[0]} which corresponds to {class_names[y_train[0]]}\")\n",
    "\n",
    "print(f\" There are {X_test.shape[0]} images which are {X_test.shape[1]} x {X_test.shape[2]} pixels. These are for testing.\")\n",
    "\n",
    "# Check that the labels are correct \n",
    "print(y_train.dtype, y_train.min(), y_train.max(), y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a186ba",
   "metadata": {},
   "source": [
    "## 2. Prepare the data\n",
    "Since pixel values in an image are in the same range [0, 255], we don't need to standarize or normalize the input data as what we did for the Indian Diebetes dataset. The only thing we are suppose to do for this dataset is to scale the pixel values down to the [0,1] range by simply dividing them by 255.0 (this also converts them to floats). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9ca39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After rescaling, an examlpe of training data X-axis pixes are: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5378702e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3833142e-04\n",
      " 1.3533257e-03 2.8911957e-03 2.6451366e-03 2.0299887e-03 1.9223376e-03\n",
      " 2.1683970e-03 3.0603614e-03 2.1991543e-03 1.3840832e-04 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.5378702e-05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# For each row of data, \n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test  = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Verify this worked\n",
    "print(f\"After rescaling, an examlpe of training data X-axis pixes are: {X_train[5][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
